// DISCLAIMER: This code was partially generated by chatGPT
package frontend.ctrl;

import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.atomic.AtomicLong;

import org.springframework.stereotype.Controller;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.ResponseBody;

@Controller
public class MetricsController {

    public static final AtomicLong indexRequests = new AtomicLong(0);
    public static final AtomicLong predictRequests = new AtomicLong(0);

    private static final double[] LATENCY_BUCKETS =
            {0.1, 0.25, 0.5, 1.0, 2.0};

    private static final ConcurrentHashMap<Double, AtomicLong> latencyBuckets =
            new ConcurrentHashMap<>();

    private static final AtomicLong latencyCount = new AtomicLong(0);
    private static volatile double latencySum = 0.0;

    static {
        for (double b : LATENCY_BUCKETS) {
            latencyBuckets.put(b, new AtomicLong(0));
        }
        latencyBuckets.put(Double.POSITIVE_INFINITY, new AtomicLong(0));
    }

    public static void observePredictionLatency(double seconds) {
        boolean bucketed = false;
        for (double b : LATENCY_BUCKETS) {
            if (seconds <= b && !bucketed) {
                latencyBuckets.get(b).incrementAndGet();
                bucketed = true;
            }
        }
        latencyBuckets.get(Double.POSITIVE_INFINITY).incrementAndGet();
        latencyCount.incrementAndGet();
        latencySum += seconds;
    }

    @GetMapping(value = "/metrics", produces = "text/plain; version=0.0.4")
    @ResponseBody
    public String metrics() {

        StringBuilder m = new StringBuilder();

        m.append("# HELP frontend_requests_total Number of frontend requests by endpoint\n");
        m.append("# TYPE frontend_requests_total counter\n");
        m.append("frontend_requests_total{endpoint=\"index\"} ")
         .append(indexRequests.get()).append("\n");
        m.append("frontend_requests_total{endpoint=\"predict\"} ")
         .append(predictRequests.get()).append("\n\n");

        m.append("# HELP prediction_ratio Ratio of predictions to index visits\n");
        m.append("# TYPE prediction_ratio gauge\n");
        double ratio = indexRequests.get() == 0
                ? 0.0
                : (double) predictRequests.get() / indexRequests.get();
        m.append("prediction_ratio ").append(ratio).append("\n\n");

        m.append("# HELP prediction_latency_seconds Prediction latency\n");
        m.append("# TYPE prediction_latency_seconds histogram\n");

        for (var e : latencyBuckets.entrySet()) {
            m.append("prediction_latency_seconds_bucket{le=\"")
             .append(e.getKey())
             .append("\"} ")
             .append(e.getValue().get())
             .append("\n");
        }

        m.append("prediction_latency_seconds_count ")
         .append(latencyCount.get()).append("\n");
        m.append("prediction_latency_seconds_sum ")
         .append(latencySum).append("\n");

        return m.toString();
    }
}
